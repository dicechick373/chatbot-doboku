from backend.llm_faiss import run_llm
import streamlit as st
from streamlit_chat import message

# proxyè¨­å®š 
# ãƒ‡ãƒ—ãƒ­ã‚¤æ™‚ã¯ã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆ
# os.environ["http_proxy"] = st.secrets["PROXY"]
# os.environ["https_proxy"] = st.secrets["PROXY"]

def vectorstore_dir(stock):
    if stock == 'åœŸæœ¨å·¥äº‹å…±é€šä»•æ§˜æ›¸':
        return "vectorstore/faiss/kyoutsuu_shiyousyo"
    elif stock == 'åœŸæœ¨è«‹è² å·¥äº‹å¿…æº':
        return "vectorstore/faiss/hikkei"
    elif stock == 'è¦ç¨‹é›†ã€é“è·¯â… ç·¨ã€‘':
        return "vectorstore/faiss/kiteisyuu/douro1"
    elif stock == 'è¦ç¨‹é›†ã€é“è·¯â…¡ç·¨ã€‘':
        return "vectorstore/faiss/kiteisyuu/douro2"
    elif stock == 'è¦ç¨‹é›†ã€æ²³å·ç·¨ã€‘':
        return "vectorstore/faiss/kiteisyuu/kasen"
    elif stock == 'è¦ç¨‹é›†ã€ç ‚é˜²ç·¨_ç ‚é˜²ã€‘':
        return "vectorstore/faiss/kiteisyuu/sabou"
    elif stock == 'è¦ç¨‹é›†ã€ç ‚é˜²ç·¨_æ€¥å‚¾æ–œã€‘':
        return "vectorstore/faiss/kiteisyuu/kyuukeisya"
    elif stock == 'è¦ç¨‹é›†ã€ç ‚é˜²ç·¨_åœ°ã™ã¹ã‚Šã€‘ ':
        return "vectorstore/faiss/kiteisyuu/jisuberi"
    elif stock == 'åœ°æ•´ä¾¿è¦§ã€åœŸæœ¨å·¥äº‹å…±é€šç·¨ã€‘':
        return "vectorstore/faiss/chiseibinran/kyoutsuu"
    elif stock == 'åœ°æ•´ä¾¿è¦§ã€é“è·¯ç·¨ã€‘ ':
        return "vectorstore/faiss/chiseibinran/douro"
    elif stock == 'åœ°æ•´ä¾¿è¦§ã€æ²³å·ç·¨ã€‘ ':
        return "vectorstore/faiss/chiseibinran/kasen"
    
# sidebar
with st.sidebar:
    openai_api_key = st.sidebar.text_input('OpenAI API Key')

    stock = st.radio(
        label='å¯¾è±¡å›³æ›¸ã‚’é¸æŠã—ã¦ãã ã•ã„',
        options=('åœŸæœ¨å·¥äº‹å…±é€šä»•æ§˜æ›¸', 'åœŸæœ¨è«‹è² å·¥äº‹å¿…æº', 'è¦ç¨‹é›†ã€é“è·¯â… ç·¨ã€‘'
                 'è¦ç¨‹é›†ã€é“è·¯â…¡ç·¨ã€‘', 'è¦ç¨‹é›†ã€æ²³å·ç·¨ã€‘','è¦ç¨‹é›†ã€ç ‚é˜²ç·¨_ç ‚é˜²ã€‘',
                 'è¦ç¨‹é›†ã€ç ‚é˜²ç·¨_æ€¥å‚¾æ–œã€‘', 'è¦ç¨‹é›†ã€ç ‚é˜²ç·¨_åœ°ã™ã¹ã‚Šã€‘',
                 'åœ°æ•´ä¾¿è¦§ã€åœŸæœ¨å·¥äº‹å…±é€šç·¨ã€‘', 'åœ°æ•´ä¾¿è¦§ã€é“è·¯ç·¨ã€‘', 'åœ°æ•´ä¾¿è¦§ã€æ²³å·ç·¨ã€‘'),
        index=0,
        # horizontal=True,
        )

    st.subheader('Link')
    "[Source Code](https://github.com/dicechick373/chatbot-doboku)"
    "[OpenAI API](https://platform.openai.com)"

# header
st.header("LangChainğŸ¦œğŸ”— doboku-model")

VECTORSTORE_DIR = vectorstore_dir(stock)

if "messages" not in st.session_state:
    st.session_state["messages"] = [
        {"role": "assistant", "content": "è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„"}]

if "chat_history" not in st.session_state:
    st.session_state["chat_history"] = []

for msg in st.session_state.messages:
    st.chat_message(msg["role"]).write(msg["content"])

if prompt := st.chat_input():
    if not st.session_state["openai_api_key"]:
        st.info("OpenAI API key ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
        st.stop()

    st.session_state.messages.append({"role": "user", "content": prompt})
    st.chat_message("user").write(prompt)
    response = run_llm(
            openai_api_key=st.session_state["openai_api_key"],
            query=prompt,
            vectordir = VECTORSTORE_DIR
        )
    msg = response['answer']
    st.session_state.messages.append({"role": "assistant", "content": msg})
    st.chat_message("assistant").write(msg)